{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83044515-22b4-4042-aa7d-86aebbf3c3dc",
   "metadata": {},
   "source": [
    "# Data Cleanup\n",
    "Now let's begin the process of cleaning up the string data we scraped from Glassdoor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "80eefc73-28a7-43d1-828b-c69e86a8dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb2ea0-8d09-41a4-b133-83508ac8f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some information on the saved data\n",
    "file_name = r\"\" # enter the filepath between the quotes\n",
    "data = pd.read_csv(file_name)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fdc22d5b-136b-4584-9b7f-725754220150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Job Title          700 non-null    object \n",
      " 1   Salary Minimum     630 non-null    object \n",
      " 2   Salary Maximum     630 non-null    object \n",
      " 3   Salary Average     630 non-null    object \n",
      " 4   Rating             657 non-null    float64\n",
      " 5   Company Name       700 non-null    object \n",
      " 6   Location           700 non-null    object \n",
      " 7   Size               670 non-null    object \n",
      " 8   Founded            564 non-null    float64\n",
      " 9   Type of ownership  670 non-null    object \n",
      " 10  Industry           638 non-null    object \n",
      " 11  Sector             638 non-null    object \n",
      " 12  Revenue            670 non-null    object \n",
      "dtypes: float64(2), object(11)\n",
      "memory usage: 71.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#We see some NaN values, so let's confirm they are recognized as nulls\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e305a3-eec5-45dc-af17-d74407896876",
   "metadata": {},
   "source": [
    "Above, we can see that some columns are fully populated, such as 'Job Title', but others have nulls. I do see some black values where there should be NaNs, so I will run through the document and replace empty cells with NaN. I will want to convert the year founded into years existing. I have to clean up some duplicates I see, convert the salary to a float and remove non numeric characters, and clean up some trailing characters at the end of the company names (/n#). It would be useful to have the location be split into city and states. I may want to clean up the string for type of ownership into just Private vs Public, but I'll run through it to confirm. Finally, I will have to review the revenue data and convert the Unknown/NA into nulls, then determine if the information can be used. **A significant and fun list!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facf08c-073f-47a4-812f-d5ee5b925292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace empty cells with NaN\n",
    "#r = raw string. ^ = start of line $ = end of line \\s* = any length of string (accounts for whitespace)\n",
    "data = data.replace(r'^\\s*$', np.nan, regex=True) # we use regex to check the cell expression and see if it matches the input\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901dc7e6-2a4e-4e02-b778-9588a33a6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking columns for nulls\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90d24b-c65b-4f13-abda-c741fe448e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove features where the salary is null,since that doesnt help us\n",
    "data_cleaned = data.dropna(axis=0,subset=['Salary Average', 'Salary Minimum'])\n",
    "data_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ac73f-38e6-4bb7-8a8c-0fb4e9381638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate hourly rows from salary rows\n",
    "data_cleaned = pd.DataFrame(data = data_cleaned) # convert the slice to a pandas dataframe to work with it\n",
    "data_cleaned['Average Hourly Rate'] = data_cleaned[\"Salary Average\"].apply(lambda x: 1 if '/hr' in x.lower() else 0)\n",
    "data_cleaned = data_cleaned.reset_index(drop=True)\n",
    "data_cleaned.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be0868-4795-4da1-8231-35a5193ac97c",
   "metadata": {},
   "source": [
    "We can see that there appears to be average hourly rate data in here. Let's split those out so we can compare the hourly rates to the salary rates givin when we analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e611c-ae14-494e-aa45-a3746e697132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up Salary min/max/average strings to only have numeric strings, then convert to float\n",
    "# remove $, ',',(/yr (est.)\n",
    "\n",
    "#First, lets clean up the Average Salary\n",
    "salary_avg = data_cleaned['Salary Average'].apply(lambda x: x.split(\"/\")[0])\n",
    "salary_avg = salary_avg.apply(lambda x: x.replace('$', '').replace(',',''))\n",
    "data_cleaned['Salary Average'] = salary_avg\n",
    "\n",
    "#Now the minimum salary\n",
    "salary_min = data_cleaned['Salary Minimum'].apply(lambda x:x.replace('$', '').replace('K','').replace('/hr', ''))\n",
    "data_cleaned['Salary Minimum']=salary_min\n",
    "\n",
    "\n",
    "#Now the maximum salary\n",
    "salary_max = data_cleaned['Salary Maximum'].apply(lambda x:x.replace('$', '').replace('K',''))\n",
    "data_cleaned['Salary Maximum']=salary_max\n",
    "data_cleaned.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40de2b-b1ab-47d4-8efa-78f2fbd0729f",
   "metadata": {},
   "source": [
    "Now lets convert the hourly values to salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d948c-8b4f-4be0-9fdb-5c4b7c6dcb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert hourly salary to yearly salary\n",
    "# convert $/hr to $/year and replace cells with the yearly estimate\n",
    "def hr_to_year(i):\n",
    "    i = int(float(i)) # convert the string to a float\n",
    "    i = i*40*52\n",
    "    #print(\"A rate of $\", i,\"/hr will be a salary of $\", int(salary),\"/yr.\")\n",
    "    return i\n",
    "\n",
    "data_cleaned[\"Converted Salary\"] = data_cleaned[\"Salary Average\"].apply(lambda x: hr_to_year(x) if x.find('.') != -1 else x)\n",
    "data_cleaned[[\"Salary Average\",\"Converted Salary\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e5e9df-f0a7-4570-b490-f3e6881a31d9",
   "metadata": {},
   "source": [
    "With the hourly rate converted to yearly salary and a column marking which rows had an hourly value, we can now move on to some simplier tasks, such as converting data types and cleaning up some strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e867c-5cb1-47ef-a9d1-d7e6545b3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trailing 5 characters from Company Name strings\n",
    "data_cleaned['Company Name'] = data_cleaned[\"Company Name\"].apply(lambda x: x.split('\\n', 1)[0] if x.find('\\n') != -1 else x)\n",
    "data_cleaned['Company Name'].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4a136b04-f289-4443-8fc7-b44e1e5833c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Remote    87\n",
       "NY        74\n",
       "CO        71\n",
       "IL        54\n",
       "CA        45\n",
       "TX        38\n",
       "PA        32\n",
       "VA        32\n",
       "GA        29\n",
       "HI        25\n",
       "FL        16\n",
       "MO        15\n",
       "OH        15\n",
       "NJ        14\n",
       "DC        13\n",
       "MN        11\n",
       "TN         9\n",
       "NC         9\n",
       "MA         8\n",
       "MI         7\n",
       "AZ         6\n",
       "RI         6\n",
       "NE         5\n",
       "IN         3\n",
       "UT         2\n",
       "SC         2\n",
       "CT         1\n",
       "MD         1\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split location to city and state\n",
    "\n",
    "\n",
    "#str(string_check.iloc[0]).split(',')[1]\n",
    "#a = 0\n",
    "#for i in DA_data_cleaned[\"Location\"]:\n",
    "#    if ',' in str(DA_data_cleaned[\"Location\"].iloc[i]):\n",
    "#        DA_data_cleaned[\"City\"] = str(DA_data_cleaned[\"Location\"].iloc[i]).split(',')[0]\n",
    "#        DA_data_cleaned[\"State\"] = str(DA_data_cleaned[\"Location\"].iloc[i]).split(',')[1]\n",
    "#        a += 1\n",
    "#    else:\n",
    "#        DA_data_cleaned[\"City\"] = \"Remote\"\n",
    "#        DA_data_cleaned[\"State\"] = \"Remote\"\n",
    "#        a +=1\n",
    "\n",
    "data_cleaned[\"City\"] = data_cleaned[\"Location\"].apply(lambda x: x.split(', ')[0])\n",
    "data_cleaned[\"State\"] = data_cleaned[\"Location\"].apply(lambda x: x.split(',')[-1] if x.find(',') != 1 else \"BAR\") \n",
    "data_cleaned[\"State\"] = data_cleaned[\"State\"].apply(lambda x: x.strip() if x.strip().lower() != 'manhattan' else 'NY')\n",
    "data_cleaned['State'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3c1b4-575d-445c-a0f5-4e04bc97b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert year founded to years in existance\n",
    "currentyear = datetime.now().year\n",
    "data_cleaned['Company Age (years)'] = data_cleaned[\"Founded\"].apply(lambda x:-1 if x==float(np.nan) else currentyear - x)\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089fffe-76c3-4e0b-a3f5-d719028d087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group jobs under archetypes (Junior v senior, analyst v business analyst)\n",
    "data_cleaned[\"Job Title\"].value_counts() # count instances of job titles occuring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640c8d2",
   "metadata": {},
   "source": [
    "We can see from above that there are already some redundancies due to small changes in the titles (eg Sr. Data Analyst ). Let's group the jobs together with a function that searches the titles and combines everything under similar banners (manager, analyst, specialist, etc). Ken Jee created some nice functions that will serve us well, so if you wish to see more here is the link: https://youtu.be/QWgg4w1SpJ8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions to bin jobs into groups\n",
    "def title_condencer(title):\n",
    "    if 'scientist' in title.lower():\n",
    "        return 'data scientist'\n",
    "    elif 'data engineer' in title.lower():\n",
    "        return 'data engineer'\n",
    "    elif 'machine learning' in title.lower():\n",
    "        return 'machine learning'\n",
    "    elif 'data scientist' in title.lower():\n",
    "        return 'data scientist'\n",
    "    elif 'analyst' in title.lower():\n",
    "        return 'analyst'\n",
    "    elif 'manager' in title.lower():\n",
    "        return 'director'\n",
    "    elif 'specialist' in title.lower():\n",
    "        return 'specialist'\n",
    "    elif 'business' in title.lower():\n",
    "        return 'business-based'\n",
    "    else:\n",
    "        return 'Unbinned'\n",
    "\n",
    "#identify if there is a seniority or level flag\n",
    "def seniority(title):\n",
    "    if 'sr' in title.lower() or 'senior' in title.lower() or 'sr.' in title.lower() or 'lead' in title.lower() or 'prinicpal' in title.lower() or 'iii' in title.lower():\n",
    "        return 'senior'\n",
    "    elif 'jr' in title.lower() or 'jr.' in title.lower() or 'junior' in title.lower():\n",
    "        return 'junior'\n",
    "    else:\n",
    "        return 'na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550310b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check binning\n",
    "data_cleaned['Job Title'] = data_cleaned['Job Title'].values.astype(str)\n",
    "data_cleaned['Title Grouping'] = data_cleaned['Job Title'].apply(title_condencer)\n",
    "data_cleaned['Title Grouping'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbf0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check seniority level\n",
    "data_cleaned['Seniority Level'] = data_cleaned['Job Title'].apply(seniority)\n",
    "data_cleaned['Seniority Level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the filename you wish to save the information as\n",
    "file = r\"\" #place the filepath between the quotes\n",
    "\n",
    "data_cleaned.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430cf8b4-2c8d-4a5e-a4fb-1a78ad6a04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for string answers for Ownership column - to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd836c45-c3cb-413f-9860-0ec83a26a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace string \"unknown/Non-applicable\" in revenue with NaN - to do"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf21297fdaca2b6fa5dfcfdc3d9e5ea3822eee823e1751c84e0320dcd6daa7a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
